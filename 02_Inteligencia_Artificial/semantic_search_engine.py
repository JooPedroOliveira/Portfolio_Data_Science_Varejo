import google.generativeai as genai
import numpy as np
import pandas as pd

# --- CONFIGURA√á√ÉO ---
MINHA_API_KEY = "INSIRA_SUA_CHAVE_AQUI"
genai.configure(api_key=MINHA_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

# --- 1. A BASE DE CONHECIMENTO ---
documentos = [
    {
        "titulo": "Troca de Roupa √çntima",
        "conteudo": "Por quest√µes de higiene e sa√∫de, n√£o realizamos troca de pe√ßas √≠ntimas (calcinhas, cuecas), exceto em caso de defeito de fabrica√ß√£o comprovado."
    },
    {
        "titulo": "Prazo de Entrega Expresso",
        "conteudo": "A entrega expressa est√° dispon√≠vel para capitais e ocorre em at√© 24 horas √∫teis ap√≥s a aprova√ß√£o do pagamento. O custo √© calculado no checkout."
    },
    {
        "titulo": "Pol√≠tica de Reembolso PIX",
        "conteudo": "Compras pagas via PIX s√£o reembolsadas na mesma conta de origem em at√© 2 horas ap√≥s a confirma√ß√£o da devolu√ß√£o no centro de distribui√ß√£o."
    },
    {
        "titulo": "Clube J&P MODAS e Vantagens",
        "conteudo": "Membros do programa de fidelidade ganham 10% de desconto na primeira compra do m√™s e acesso antecipado a cole√ß√µes exclusivas."
    }
]

df = pd.DataFrame(documentos)

# --- 2. CRIANDO OS EMBEDDINGS (VERS√ÉO COMPAT√çVEL) ---
def gerar_embedding(texto):
    # Removemos o 'task_type' para evitar conflitos com vers√µes diferentes de modelos
    return genai.embed_content(
        model="models/gemini-embedding-001", 
        content=texto
    )["embedding"]

print("üßÆ Vetorizando a base de conhecimento (Indexa√ß√£o)...")
try:
    df['vetor'] = df['conteudo'].apply(gerar_embedding)
    print("‚úÖ Base indexada! Cada texto agora √© uma lista de n√∫meros.")
except Exception as e:
    print(f"‚ùå Erro na vetoriza√ß√£o: {e}")
    exit()

# --- 3. SISTEMA DE BUSCA ---
def buscar_melhor_resposta(pergunta_usuario):
    # 1. Vetoriza a pergunta
    vetor_pergunta = genai.embed_content(
        model="models/gemini-embedding-001",
        content=pergunta_usuario
    )["embedding"]
    
    # 2. Matem√°tica: Produto Escalar
    produtos_escalares = []
    
    for vetor_doc in df['vetor']:
        score = np.dot(vetor_pergunta, vetor_doc)
        produtos_escalares.append(score)
    
    df['score_similaridade'] = produtos_escalares
    df_ordenado = df.sort_values('score_similaridade', ascending=False)
    
    melhor_doc = df_ordenado.iloc[0]
    return melhor_doc

# --- 4. INTERFACE DO CHATBOT ---
print("\nü§ñ CHATBOT ENTERPRISE (Baseado em Vetores)")
print("Este bot l√™ apenas o par√°grafo necess√°rio, economizando 99% de tokens.")

while True:
    pergunta = input("\nPergunta: ")
    if pergunta.lower() == "sair":
        break
        
    try:
        # Passo A: O "Retrieval"
        doc_encontrado = buscar_melhor_resposta(pergunta)
        
        print(f"   [DEBUG] T√≥pico Recuperado: '{doc_encontrado['titulo']}' (Score: {doc_encontrado['score_similaridade']:.4f})")
        
        # Passo B: A Gera√ß√£o
        prompt = f"""
        Voc√™ √© um assistente virtual. Responda √† pergunta do usu√°rio usando APENAS o contexto abaixo.
        
        CONTEXTO OFICIAL:
        {doc_encontrado['conteudo']}
        
        PERGUNTA: {pergunta}
        """
        
        response = model.generate_content(prompt)
        print(f"ü§ñ Resposta: {response.text}")
        
    except Exception as e:
        print(f"Erro na execu√ß√£o: {e}")