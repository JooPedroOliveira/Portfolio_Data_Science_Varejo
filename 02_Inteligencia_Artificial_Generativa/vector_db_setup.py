import google.generativeai as genai
import pandas as pd
import chromadb
from chromadb.config import Settings

# --- CONFIGURA√á√ÉO ---
MINHA_API_KEY = "INSIRA_SUA_CHAVE_AQUI"
genai.configure(api_key=MINHA_API_KEY)

# --- 1. CONFIGURANDO O BANCO VETORIAL (PERSISTENTE) ---
# Isso cria uma pasta 'banco_vetorial_ca' no seu computador.
# Os dados ficam salvos l√° para sempre!
chroma_client = chromadb.PersistentClient(path="banco_vetorial_jp_modas")

# Criamos uma "cole√ß√£o" (√© como se fosse uma Tabela SQL)
nome_colecao = "produtos_jp_modas"

# O get_or_create garante que n√£o vamos apagar dados se rodarmos de novo
collection = chroma_client.get_or_create_collection(name=nome_colecao)

# --- 2. FUN√á√ÉO DE EMBEDDING (GEMINI) ---
def gerar_embedding(texto):
    try:
        return genai.embed_content(
            model="models/gemini-embedding-001", # O modelo que funcionou pra voc√™
            content=texto
        )["embedding"]
    except Exception as e:
        print(f"Erro ao vetorizar: {e}")
        return []

# --- 3. INGEST√ÉO DE DADOS (ETL) ---
# Vamos verificar se o banco j√° est√° cheio para n√£o duplicar
if collection.count() == 0:
    print("üìÇ Banco vazio! Iniciando carga de dados do CSV...")
    
    # Lendo o CSV que voc√™ criou
    df = pd.read_csv('produtos_1000_precos_realistas.csv')
    
    # Para o teste ser r√°pido, vamos carregar apenas os primeiros 20 produtos
    # Num cen√°rio real, far√≠amos um loop no milh√£o de linhas
    df_amostra = df.head(20) 
    
    ids = []
    documentos = [] # O texto que ser√° buscado
    metadados = [] # Dados extras (pre√ßo, categoria) para filtrar depois
    vetores = []
    
    print("‚è≥ Gerando vetores (Isso pode levar alguns segundos)...")
    for index, row in df_amostra.iterrows():
        # Criamos um "texto rico" para a IA entender o produto
        texto_produto = f"{row['nome']} - {row['categoria']} - {row['descricao']}"
        
        # Geramos a matem√°tica
        vetor = gerar_embedding(texto_produto)
        
        if vetor:
            ids.append(str(row['id']))
            documentos.append(texto_produto)
            metadados.append({"preco": row['preco'], "categoria": row['categoria']})
            vetores.append(vetor)
            print(f"   Processado: {row['nome']}")

    # Salvando tudo no ChromaDB de uma vez (Batch Insert)
    collection.add(
        ids=ids,
        documents=documentos,
        embeddings=vetores,
        metadatas=metadados
    )
    print(f"‚úÖ Sucesso! {len(ids)} produtos indexados no ChromaDB.")

else:
    print(f"‚ö° Banco carregado! Total de documentos: {collection.count()}")


# --- 4. O MOTOR DE BUSCA (SEARCH ENGINE) ---
print("\nüîç MOTOR DE BUSCA SEM√ÇNTICA J&P MODAS")
print("Dica: Tente buscar por 'roupa para festa' ou 'algo confort√°vel'.")

while True:
    query = input("\nO que voc√™ procura? (ou 'sair'): ")
    if query.lower() == "sair":
        break
    
    # 1. Vetorizamos a pergunta do usu√°rio
    vetor_pergunta = gerar_embedding(query)
    
    # 2. O Chroma faz a busca matem√°tica super r√°pida
    resultados = collection.query(
        query_embeddings=[vetor_pergunta],
        n_results=3 # Traz os 3 melhores
    )
    
    # 3. Exibi√ß√£o dos Resultados
    print("\nüéØ PRODUTOS ENCONTRADOS:")
    
    # O Chroma retorna listas dentro de listas, ent√£o precisamos iterar
    for i in range(len(resultados['ids'][0])):
        id_prod = resultados['ids'][0][i]
        texto = resultados['documents'][0][i]
        meta = resultados['metadatas'][0][i]
        distancia = resultados['distances'][0][i] # Quanto menor, mais similar
        
        print(f"   üõí [{id_prod}] {texto}")
        print(f"      Pre√ßo: R$ {meta['preco']} | Categoria: {meta['categoria']}")
        print("-" * 40)