import google.generativeai as genai
import chromadb
import time

# ==============================================================================
# ‚öôÔ∏è CONFIGURA√á√ÉO DO APP
# ==============================================================================
MINHA_API_KEY = "INSIRA_SUA_CHAVE_AQUI"

# Modelos de elite
MODELO_CHAT = "models/gemini-2.5-flash" 
MODELO_EMBEDDING = "models/gemini-embedding-001"

genai.configure(api_key=MINHA_API_KEY)
modelo_inteligente = genai.GenerativeModel(MODELO_CHAT)

# Conecta no MESMO banco que o ETL criou
print("üîå Conectando ao Banco de Dados Enterprise...")
chroma_client = chromadb.PersistentClient(path="banco_vetorial_jp_modas")
collection = chroma_client.get_collection(name="estoque_vip_jp_modas")

total_produtos = collection.count()
print(f"‚úÖ Sistema Online! {total_produtos} produtos dispon√≠veis no estoque.")

# ==============================================================================
# ü§ñ LOOP DO VENDEDOR
# ==============================================================================
print("\n" + "="*60)
print(f"üëî VENDEDOR VIRTUAL J&P MODAS (Gemini 2.5 Pro)")
print("="*60)

while True:
    pergunta = input("\nüë§ Cliente: ")
    if pergunta.lower() in ["sair", "fim"]:
        print("üëã At√© logo!")
        break

    print("üîé Procurando as melhores op√ß√µes...")
    
    try:
        # 1. Busca Sem√¢ntica (Retrieval)
        # Aqui usamos o embedding s√≥ para a pergunta (1 token, super barato)
        vetor_pergunta = genai.embed_content(model=MODELO_EMBEDDING, content=pergunta)["embedding"]
        
        # Traz os 4 produtos mais relevantes
        resultados = collection.query(query_embeddings=[vetor_pergunta], n_results=4)
        
        # 2. Montagem do Contexto (Grounding)
        contexto = ""
        # Verifica se achou algo
        if not resultados['ids'][0]:
            print("‚ùå N√£o encontrei produtos similares.")
            continue

        for i in range(len(resultados['ids'][0])):
            item = resultados['documents'][0][i]
            meta = resultados['metadatas'][0][i]
            contexto += f"- {item} | Pre√ßo: R$ {meta['preco']:.2f}\n"

        # 3. Gera√ß√£o da Resposta (Generation)
        prompt = f"""
        Voc√™ √© um Personal Stylist e Vendedor S√™nior de um grande varejista de moda.
        
        PERFIL DO CLIENTE (O que ele pediu): "{pergunta}"
        
        OP√á√ïES DISPON√çVEIS NO ESTOQUE:
        {contexto}
        
        SUA MISS√ÉO:
        Recomende a melhor op√ß√£o da lista acima para este cliente.
        Use uma linguagem persuasiva, elegante e simp√°tica (use emojis).
        Justifique a escolha conectando a descri√ß√£o do produto com o desejo do cliente.
        Se o cliente perguntou algo fora do contexto de roupa, diga gentilmente que s√≥ vende moda.
        """
        
        response = modelo_inteligente.generate_content(prompt)
        print(f"\nü§ñ Gemini 2.5 Pro:\n{response.text}")
        
    except Exception as e:
        print(f"‚ùå Erro tempor√°rio: {e}")
        print("Dica: Se for erro 429, espere 1 minuto e tente de novo.")